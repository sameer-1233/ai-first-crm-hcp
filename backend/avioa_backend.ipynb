{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn langgraph langchain groq sqlalchemy pydantic psycopg2-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-trOtugilCi",
        "outputId": "7b86d8a9-b047-4902-a05a-814907b152c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.40.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.45)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.2.6)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.1)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.6.1)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary, groq\n",
            "Successfully installed groq-1.0.0 psycopg2-binary-2.9.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuDd_ZDngDhk",
        "outputId": "8c1c1039-a6f2-477c-badc-187aa2cd704c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.40.0)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.45)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.12/dist-packages (2.9.11)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.2.6)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.1)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.6.1)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn langgraph langchain groq sqlalchemy psycopg2-binary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iujsyqY87rBY",
        "outputId": "355a204f-5ce3-45f8-9f36-57d53e5fa542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uvicorn backend.main:app --reload --port 8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBedJ4JO1MEo",
        "outputId": "cccaeb39-425d-44cf-dcf0-c9686e05b7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m7727\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n",
            "Process SpawnProcess-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/_subprocess.py\", line 80, in subprocess_started\n",
            "    target(sockets=sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 67, in run\n",
            "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 195, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 71, in serve\n",
            "    await self._serve(sockets)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/server.py\", line 78, in _serve\n",
            "    config.load()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/config.py\", line 439, in load\n",
            "    self.loaded_app = import_from_string(self.app)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 22, in import_from_string\n",
            "    raise exc from None\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/importer.py\", line 19, in import_from_string\n",
            "    module = importlib.import_module(module_str)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1324, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'backend'\n",
            "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m7727\u001b[0m]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backend/main.py\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI(title=\"AI-First CRM HCP\")\n",
        "\n",
        "class ChatInput(BaseModel):\n",
        "    message: str\n",
        "\n",
        "@app.post(\"/interaction/chat\")\n",
        "def chat_interaction(data: ChatInput):\n",
        "    return {\n",
        "        \"status\": \"received\",\n",
        "        \"message\": data.message\n",
        "    }\n"
      ],
      "metadata": {
        "id": "VchU8NsGgJCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backend/agent/agent.py\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "class AgentState(dict):\n",
        "    pass\n",
        "\n",
        "def router(state):\n",
        "    return \"log_interaction\"\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"router\", router)\n",
        "graph.set_entry_point(\"router\")\n",
        "agent = graph.compile()\n"
      ],
      "metadata": {
        "id": "UZxOlorVgqZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Log Interaction"
      ],
      "metadata": {
        "id": "wwrqabcWhQMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backend/tools/log_interaction.py\n",
        "def log_interaction_tool(text: str):\n",
        "    return {\n",
        "        \"hcp_name\": \"Dr. Sharma\",\n",
        "        \"specialty\": \"Cardiology\",\n",
        "        \"product\": \"Drug X\",\n",
        "        \"summary\": \"Doctor showed interest\",\n",
        "        \"sentiment\": \"Positive\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "gUmilex8g7_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_interaction_tool(interaction_id: int, updated_text: str):\n",
        "    return {\n",
        "        \"interaction_id\": interaction_id,\n",
        "        \"status\": \"updated\"\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TT4bl9IheKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_interactions_tool():\n",
        "    return \"This week: 10 interactions, 7 positive.\""
      ],
      "metadata": {
        "id": "Jxlpp6R7he3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def followup_recommendation_tool():\n",
        "    return \"Schedule follow-up visit in 2 weeks.\""
      ],
      "metadata": {
        "id": "e01KUOWMhife"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compliance_check_tool(text: str):\n",
        "    return \"No compliance risks detected.\"\n"
      ],
      "metadata": {
        "id": "eLYaOjeZhrLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_PATH = \"/content/ai_crm_hcp\"\n",
        "BACKEND_PATH = os.path.join(BASE_PATH, \"backend\")\n",
        "\n",
        "os.makedirs(BACKEND_PATH, exist_ok=True)\n",
        "\n",
        "open(os.path.join(BACKEND_PATH, \"__init__.py\"), \"w\").close()\n",
        "\n",
        "print(\"Folders created\")\n",
        "print(os.listdir(BASE_PATH))\n",
        "print(os.listdir(BACKEND_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMiPz6l3yRim",
        "outputId": "9358f3c0-571d-46be-d541-d0067e02dba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created\n",
            "['backend']\n",
            "['__init__.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/database.py\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import sessionmaker, declarative_base\n",
        "\n",
        "DATABASE_URL = \"sqlite:///./crm.db\"\n",
        "\n",
        "engine = create_engine(\n",
        "    DATABASE_URL,\n",
        "    connect_args={\"check_same_thread\": False}\n",
        ")\n",
        "\n",
        "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
        "\n",
        "Base = declarative_base()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDIBXIRGvpKC",
        "outputId": "605c4cf0-3c01-41f1-b51d-1d3c3cd09742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/database.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/models.py\n",
        "from sqlalchemy import Column, Integer, String, DateTime\n",
        "from datetime import datetime\n",
        "\n",
        "from backend.database import Base\n",
        "\n",
        "class Interaction(Base):\n",
        "    __tablename__ = \"interactions\"\n",
        "\n",
        "    id = Column(Integer, primary_key=True, index=True)\n",
        "    hcp_name = Column(String, nullable=False)\n",
        "    specialty = Column(String)\n",
        "    product = Column(String)\n",
        "    summary = Column(String)\n",
        "    sentiment = Column(String)\n",
        "    created_at = Column(DateTime, default=datetime.utcnow)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxZMx_r1ykNp",
        "outputId": "a27afc69-1d06-444c-e37b-702eac11c15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/models.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/ai_crm_hcp\")\n",
        "\n",
        "print(sys.path[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Jget18yp7C",
        "outputId": "4ae2ce1e-109f-4b20-afc9-c4a17796ae2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai_crm_hcp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from backend.database import Base, engine\n",
        "from backend.models import Interaction\n",
        "\n",
        "print(\"✅ Import successful\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESTVkKtGyubm",
        "outputId": "2ea05ead-0407-4cd2-f8e0-138c61a2a3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Import successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from backend.database import engine\n",
        "from backend.models import Base\n",
        "\n",
        "Base.metadata.create_all(bind=engine)\n",
        "\n",
        "print(\"✅ Database tables created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evPstzkbyx8L",
        "outputId": "a795dc87-26ff-4d90-a054-7de92891b654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Database tables created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "backend/llm/groq_client.py"
      ],
      "metadata": {
        "id": "vec-i3LN6nfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n"
      ],
      "metadata": {
        "id": "X9hJXQLq_XMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/ai_crm_hcp\")\n"
      ],
      "metadata": {
        "id": "iRpM_KzL_gwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groq client must read from environment variables.\n",
        "Uses Groq\n",
        "Uses llama-3.3-70b-versatile model"
      ],
      "metadata": {
        "id": "K955faPH8L4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "def get_groq_client():\n",
        "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY not set\")\n",
        "    return Groq(api_key=api_key)\n",
        "\n",
        "def call_llm(prompt: str) -> str:\n",
        "    client = get_groq_client()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",  #  SUPPORTED MODEL\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a healthcare CRM assistant.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "ln0J_2Dj_-5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/llm/groq_client.py\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "def get_groq_client():\n",
        "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY not set\")\n",
        "    return Groq(api_key=api_key)\n",
        "\n",
        "def call_llm(prompt: str) -> str:\n",
        "    client = get_groq_client()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a healthcare CRM assistant.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUQ5D5trAbuL",
        "outputId": "1249be03-7674-44c2-e395-2d1df080058c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/llm/groq_client.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE = \"/content/ai_crm_hcp/backend/llm\"\n",
        "os.makedirs(BASE, exist_ok=True)\n",
        "\n",
        "open(os.path.join(BASE, \"__init__.py\"), \"w\").close()\n",
        "\n",
        "print(\"llm folder contents:\", os.listdir(BASE))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53eee46O9LtG",
        "outputId": "158d33ca-5884-42d8-e829-5fda01a4a259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm folder contents: ['__init__.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/ai_crm_hcp\")\n",
        "\n",
        "print(sys.path[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_p-46-D9di5",
        "outputId": "ca06199b-dbf2-4413-ac1b-fff5ff98fe57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai_crm_hcp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from backend.llm.groq_client import call_llm\n",
        "\n",
        "response = call_llm(\n",
        "    \"Summarize this sales interaction: Met a cardiologist and discussed a new hypertension drug.\"\n",
        ")\n",
        "\n",
        "print(\"✅ Groq response:\")\n",
        "print(response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaVs0Yk38o9r",
        "outputId": "4acf77be-0c5d-4c0b-81bc-7ecb25188aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Groq response:\n",
            "Here's a summary of the sales interaction:\n",
            "\n",
            "**Interaction Type:** Sales Meeting\n",
            "**Healthcare Professional:** Cardiologist\n",
            "**Topic:** New Hypertension Drug\n",
            "**Outcome:** Discussed the features and benefits of the new hypertension drug with the cardiologist.\n",
            "\n",
            "Next steps could include:\n",
            "- Following up with the cardiologist to answer any additional questions\n",
            "- Providing samples or more information about the drug\n",
            "- Discussing potential prescribing habits and addressing any concerns the cardiologist may have.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENT LANGGRAPH AGENT"
      ],
      "metadata": {
        "id": "Ll34UDn6DURd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "AGENT_PATH = \"/content/ai_crm_hcp/backend/agent\"\n",
        "os.makedirs(AGENT_PATH, exist_ok=True)\n",
        "\n",
        "open(os.path.join(AGENT_PATH, \"__init__.py\"), \"w\").close()\n",
        "\n",
        "print(\"agent folder contents:\", os.listdir(AGENT_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc6Q7MqbEYVv",
        "outputId": "eff9fc40-e18f-45a8-dc65-edeb60298cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent folder contents: ['__init__.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/agent/state.py\n",
        "from typing import TypedDict, Optional, Any\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    user_input: str\n",
        "    intent: Optional[str]\n",
        "    result: Optional[Any]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v61WwFjPEZv-",
        "outputId": "967bb558-21ef-4894-ae5c-401029b70ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/agent/state.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/agent/graph.py\n",
        "from langgraph.graph import StateGraph, END\n",
        "from backend.agent.state import AgentState\n",
        "\n",
        "from backend.tools.log_interaction import log_interaction_tool\n",
        "from backend.tools.edit_interaction import edit_interaction_tool\n",
        "from backend.tools.summarize import summarize_interactions_tool\n",
        "from backend.tools.followup import followup_recommendation_tool\n",
        "from backend.tools.compliance import compliance_check_tool\n",
        "\n",
        "\n",
        "def detect_intent(state: AgentState) -> AgentState:\n",
        "    text = state[\"user_input\"].lower()\n",
        "\n",
        "    if \"edit\" in text:\n",
        "        state[\"intent\"] = \"edit\"\n",
        "    elif \"summary\" in text:\n",
        "        state[\"intent\"] = \"summary\"\n",
        "    elif \"follow\" in text:\n",
        "        state[\"intent\"] = \"followup\"\n",
        "    elif \"compliance\" in text or \"off-label\" in text:\n",
        "        state[\"intent\"] = \"compliance\"\n",
        "    else:\n",
        "        state[\"intent\"] = \"log\"\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def log_node(state: AgentState) -> AgentState:\n",
        "    state[\"result\"] = log_interaction_tool(state[\"user_input\"])\n",
        "    return state\n",
        "\n",
        "\n",
        "def edit_node(state: AgentState) -> AgentState:\n",
        "    state[\"result\"] = edit_interaction_tool(\n",
        "        interaction_id=1,\n",
        "        new_summary=\"Updated by LangGraph\"\n",
        "    )\n",
        "    return state\n",
        "\n",
        "\n",
        "def summary_node(state: AgentState) -> AgentState:\n",
        "    state[\"result\"] = summarize_interactions_tool()\n",
        "    return state\n",
        "\n",
        "\n",
        "def followup_node(state: AgentState) -> AgentState:\n",
        "    state[\"result\"] = followup_recommendation_tool()\n",
        "    return state\n",
        "\n",
        "\n",
        "def compliance_node(state: AgentState) -> AgentState:\n",
        "    state[\"result\"] = compliance_check_tool(state[\"user_input\"])\n",
        "    return state\n",
        "\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"router\", detect_intent)\n",
        "graph.add_node(\"log\", log_node)\n",
        "graph.add_node(\"edit\", edit_node)\n",
        "graph.add_node(\"summary\", summary_node)\n",
        "graph.add_node(\"followup\", followup_node)\n",
        "graph.add_node(\"compliance\", compliance_node)\n",
        "\n",
        "graph.set_entry_point(\"router\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"router\",\n",
        "    lambda state: state[\"intent\"],\n",
        "    {\n",
        "        \"log\": \"log\",\n",
        "        \"edit\": \"edit\",\n",
        "        \"summary\": \"summary\",\n",
        "        \"followup\": \"followup\",\n",
        "        \"compliance\": \"compliance\",\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(\"log\", END)\n",
        "graph.add_edge(\"edit\", END)\n",
        "graph.add_edge(\"summary\", END)\n",
        "graph.add_edge(\"followup\", END)\n",
        "graph.add_edge(\"compliance\", END)\n",
        "\n",
        "agent = graph.compile()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuEfLT0qEeRL",
        "outputId": "11a81778-e0fb-4a92-febb-0cadcd4bb23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/agent/graph.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/ai_crm_hcp\")\n"
      ],
      "metadata": {
        "id": "GKxqsR3mEn0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TOOLS_PATH = \"/content/ai_crm_hcp/backend/tools\"\n",
        "os.makedirs(TOOLS_PATH, exist_ok=True)\n",
        "\n",
        "open(os.path.join(TOOLS_PATH, \"__init__.py\"), \"w\").close()\n",
        "\n",
        "print(\"tools folder contents:\", os.listdir(TOOLS_PATH))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G1xqlIBJNEB",
        "outputId": "4418ea50-d69c-4c5d-b604-561ef084981e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tools folder contents: ['__init__.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "if \"/content/ai_crm_hcp\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/ai_crm_hcp\")\n",
        "\n",
        "print(sys.path[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz_rQJCdJatz",
        "outputId": "521d0f8e-304c-482c-c9bd-e35b76fbc3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai_crm_hcp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "\n",
        "import backend\n",
        "import backend.tools\n",
        "import backend.agent\n",
        "\n",
        "importlib.reload(backend)\n",
        "importlib.reload(backend.tools)\n",
        "importlib.reload(backend.agent)\n",
        "\n",
        "print(\"✅ Packages reloaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIphRZx3JfXI",
        "outputId": "c2544469-4da0-47ea-9d67-433b88fb2bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Packages reloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/tools/log_interaction.py\n",
        "from backend.llm.groq_client import call_llm\n",
        "from backend.database import SessionLocal\n",
        "from backend.models import Interaction\n",
        "\n",
        "def log_interaction_tool(user_text: str):\n",
        "    summary = call_llm(user_text)\n",
        "\n",
        "    interaction = Interaction(\n",
        "        hcp_name=\"Dr. Sharma\",\n",
        "        specialty=\"Cardiology\",\n",
        "        product=\"Hypertension Drug\",\n",
        "        summary=summary,\n",
        "        sentiment=\"Positive\"\n",
        "    )\n",
        "\n",
        "    db = SessionLocal()\n",
        "    db.add(interaction)\n",
        "    db.commit()\n",
        "    db.refresh(interaction)\n",
        "    db.close()\n",
        "\n",
        "    return {\n",
        "        \"status\": \"logged\",\n",
        "        \"interaction_id\": interaction.id\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX3fkIT8LP2N",
        "outputId": "3079592b-dc3a-469b-8a91-227929522f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/tools/log_interaction.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/tools/edit_interaction.py\n",
        "from backend.database import SessionLocal\n",
        "from backend.models import Interaction\n",
        "\n",
        "def edit_interaction_tool(interaction_id: int, new_summary: str):\n",
        "    db = SessionLocal()\n",
        "    interaction = db.query(Interaction).filter(\n",
        "        Interaction.id == interaction_id\n",
        "    ).first()\n",
        "\n",
        "    if not interaction:\n",
        "        return {\"error\": \"Interaction not found\"}\n",
        "\n",
        "    interaction.summary = new_summary\n",
        "    db.commit()\n",
        "    db.close()\n",
        "\n",
        "    return {\n",
        "        \"status\": \"updated\",\n",
        "        \"interaction_id\": interaction_id\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PValBHGiLUh2",
        "outputId": "585ad063-b557-4a23-95ca-0216a45e6243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/tools/edit_interaction.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/tools/summarize.py\n",
        "from backend.database import SessionLocal\n",
        "from backend.models import Interaction\n",
        "\n",
        "def summarize_interactions_tool():\n",
        "    db = SessionLocal()\n",
        "    count = db.query(Interaction).count()\n",
        "    db.close()\n",
        "    return f\"Total interactions logged: {count}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoMiliJyLZSp",
        "outputId": "4319b78f-ecfd-45ad-c08b-3ab19e312a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/tools/summarize.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/tools/followup.py\n",
        "def followup_recommendation_tool():\n",
        "    return \"Recommended follow-up in 2 weeks with product samples.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoLD69fjLi8B",
        "outputId": "8196b7c3-08d2-44c5-a14b-524e26bd258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/tools/followup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, importlib\n",
        "\n",
        "sys.path.insert(0, \"/content/ai_crm_hcp\")\n",
        "\n",
        "import backend.tools\n",
        "importlib.reload(backend.tools)\n",
        "\n",
        "print(\"✅ tools package loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbMaIvDMLlIk",
        "outputId": "c9835cec-79b0-47c5-ba0e-ae6f8c551c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ tools package loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TOOLS_PATH = \"/content/ai_crm_hcp/backend/tools\"\n",
        "os.makedirs(TOOLS_PATH, exist_ok=True)\n",
        "\n",
        "# ensure __init__.py exists\n",
        "open(os.path.join(TOOLS_PATH, \"__init__.py\"), \"a\").close()\n",
        "\n",
        "with open(os.path.join(TOOLS_PATH, \"compliance.py\"), \"w\") as f:\n",
        "    f.write(\n",
        "        'def compliance_check_tool(text: str):\\n'\n",
        "        '    if \"off-label\" in text.lower():\\n'\n",
        "        '        return \"⚠️ Potential compliance issue detected\"\\n'\n",
        "        '    return \"No compliance issues detected\"\\n'\n",
        "    )\n",
        "\n",
        "print(\"✅ compliance.py created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62cMKm57w4no",
        "outputId": "452d8c97-a47b-4a68-f2f0-6c052ebd570c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ compliance.py created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from backend.agent.graph import agent\n",
        "\n",
        "result = agent.invoke({\n",
        "    \"user_input\": \"Met Dr. Sharma, cardiologist, discussed hypertension drug. He was interested.\"\n",
        "})\n",
        "\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRLalF-fLq95",
        "outputId": "7d0edc1a-2d29-4c2d-f10d-847ac8b60142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'user_input': 'Met Dr. Sharma, cardiologist, discussed hypertension drug. He was interested.', 'intent': 'log', 'result': {'status': 'logged', 'interaction_id': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke({\"user_input\": \"Give me a summary\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wuIynWlzI-Q",
        "outputId": "dcffd667-f46e-4efc-e1a9-5972d4f9122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_input': 'Give me a summary',\n",
              " 'intent': 'summary',\n",
              " 'result': 'Total interactions logged: 1'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke({\"user_input\": \"What follow-up should I do?\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7zWGDkozp4E",
        "outputId": "e90f5cd0-179e-42b2-8c97-2a1fade1fcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_input': 'What follow-up should I do?',\n",
              " 'intent': 'followup',\n",
              " 'result': 'Recommended follow-up in 2 weeks with product samples.'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAST API"
      ],
      "metadata": {
        "id": "DUxPLW2kzsZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ai_crm_hcp/backend/main.py\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from backend.agent.graph import agent\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"AI-First CRM – HCP Module\",\n",
        "    description=\"Log HCP interactions using LangGraph + LLM\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Request Schemas\n",
        "# -------------------------\n",
        "class InteractionRequest(BaseModel):\n",
        "    user_input: str\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Health Check\n",
        "# -------------------------\n",
        "@app.get(\"/\")\n",
        "def health_check():\n",
        "    return {\"status\": \"API is running\"}\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Core Endpoint (LangGraph)\n",
        "# -------------------------\n",
        "@app.post(\"/interaction\")\n",
        "def handle_interaction(request: InteractionRequest):\n",
        "    \"\"\"\n",
        "    This endpoint sends user input to the LangGraph agent\n",
        "    and returns the agent's structured response.\n",
        "    \"\"\"\n",
        "    result = agent.invoke({\n",
        "        \"user_input\": request.user_input\n",
        "    })\n",
        "    return result\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6gRgfs71CMW",
        "outputId": "f239a8b3-fe92-47b6-c700-40cdc640e403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/ai_crm_hcp/backend/main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "“Since I was working in a notebook environment, I validated my FastAPI endpoints using FastAPI’s TestClient, which allows end-to-end API testing without running a live server.”"
      ],
      "metadata": {
        "id": "9_S0eaco2xbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi.testclient import TestClient\n",
        "from backend.main import app\n",
        "\n",
        "client = TestClient(app)\n",
        "\n",
        "response = client.post(\n",
        "    \"/interaction\",\n",
        "    json={\n",
        "        \"user_input\": \"Met Dr. Sharma, cardiologist, discussed hypertension drug. He was interested.\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqq8V5k71FS2",
        "outputId": "1b7e546e-fa61-4b0e-a71c-450a6c064082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'user_input': 'Met Dr. Sharma, cardiologist, discussed hypertension drug. He was interested.', 'intent': 'log', 'result': {'status': 'logged', 'interaction_id': 2}}\n"
          ]
        }
      ]
    }
  ]
}